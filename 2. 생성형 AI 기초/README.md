# 생성형 AI
기존의 데이터를 학습하여 <br>
학습된 패턴과 정보를 바탕으로 <br>
새로운 콘텐츠(텍스트, 이미지, 음악, 영상, 코드 등)를 생성 <br>
<br>
작동 원리는 크게 아키텍처, 프로세스, 모델의 세 가지 관점에서 이해할 수 있음

* 아키텍처 : 모델의 기본적인 구조를 정의
* 프로세스 : 데이터를 학습하고 새로운 콘텐츠를 생성하는 단계를 설명
* 모델 : 특정 작업에 특화된 학습된 신경망을 의미<br><br>
## 목차
[1. 입력된 텍스트](#1-입력된-텍스트)<br>
[2. 질문에 대한 텍스트 답을 내는 과정](#2-질문에-대한-텍스트-답을-내는-과정)<br>
[3. 데이터 학습](#3-데이터-학습)<br>
[4. Transformer](#4-Transformer)<br><br>



## 1. 입력된 텍스트
입력된 텍스트는 모델이 이해할 수 있는 형태로 변환 <br>
<br>
**토큰화(Tokenization)** <br>
텍스트는 의미를 가지는 작은 단위인 토큰(일반적으로 단어나 서브워드)으로 분리(토큰 시퀀스) <br>
예: “안녕하세요, GPT-3.5 Turbo님.” → [“안녕하세요”, “,”, “GPT-3”, “.”, “5”, “Turbo”, “님”, “.”] <br>
<br>
**벡터화**<br>
토큰화된 각 토큰은 임베딩(Embedding)이라는 과정을 통해 고차원 벡터 공간의 한 점으로 표현<br>
( 임베딩 벡터는 각 토큰의 의미와 문맥 정보를 담고 있음 ) <br><br>

## 2. 질문에 대한 텍스트 답을 내는 과정
텍스트 답은 단어단위로 만들어진다. <br>
이전까지 생성된 단어와, 기타( 엄청 복잡함 ) 다른 정보들을 바탕으로 **확률적으로 가장 높은 단어가 다음 단어로 채택** 된다. <br><br>



## 3. 데이터 학습
샘플들 주고 옳바른 답이 나올때까지 훈련시키기도 함
> 해당 답을 얻는 경로로 노드들이 연결됨

<br>

## 4. Transformer
생성형 ai 아키텍쳐의 일종<br>
인코더(encoder)와 디코더(decoder)로 구성<br>
<br>
인코더는 입력 시퀀스를 이해 <br>
디코더는 인코더의 출력을 기반으로 새로운 시퀀스를 생성<br>
<br>
디코더에서 이전까지 생성된 단어와 인코더의 정보를 바탕으로 다음 단어를 예측<br>
<br>
데이터 압축, 프롬프트 기반으로 데이터 재구성
